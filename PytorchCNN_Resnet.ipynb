{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-26T11:59:56.294915Z","iopub.execute_input":"2023-01-26T11:59:56.295252Z","iopub.status.idle":"2023-01-26T11:59:56.320256Z","shell.execute_reply.started":"2023-01-26T11:59:56.295175Z","shell.execute_reply":"2023-01-26T11:59:56.319438Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dsp-project/portrait_emotions_labels.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:00:49.759548Z","iopub.execute_input":"2023-01-26T12:00:49.759920Z","iopub.status.idle":"2023-01-26T12:00:49.798069Z","shell.execute_reply.started":"2023-01-26T12:00:49.759891Z","shell.execute_reply":"2023-01-26T12:00:49.797130Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"             filename  emotion  label\n0     image_06637.jpg    angry      1\n1     image_06638.jpg    angry      1\n2     image_06639.jpg  disgust      6\n3     image_06641.jpg  neutral      7\n4     image_06642.jpg      sad      2\n...               ...      ...    ...\n5831  image_08036.jpg    angry      1\n5832  image_08035.jpg  neutral      7\n5833  image_08038.jpg      sad      2\n5834  image_08028.jpg     fear      4\n5835  image_08026.jpg    angry      1\n\n[5836 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_06637.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_06638.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_06639.jpg</td>\n      <td>disgust</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_06641.jpg</td>\n      <td>neutral</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_06642.jpg</td>\n      <td>sad</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5831</th>\n      <td>image_08036.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5832</th>\n      <td>image_08035.jpg</td>\n      <td>neutral</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5833</th>\n      <td>image_08038.jpg</td>\n      <td>sad</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5834</th>\n      <td>image_08028.jpg</td>\n      <td>fear</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5835</th>\n      <td>image_08026.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5836 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/dsp-project/rijks_emotion_cluster1.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:00:53.460930Z","iopub.execute_input":"2023-01-26T12:00:53.461372Z","iopub.status.idle":"2023-01-26T12:00:53.485339Z","shell.execute_reply.started":"2023-01-26T12:00:53.461332Z","shell.execute_reply":"2023-01-26T12:00:53.484462Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        filename    emotion\n0      img_1.jpg  surprised\n1     img_10.jpg    disgust\n2    img_100.jpg      angry\n3    img_101.jpg       fear\n4    img_102.jpg      angry\n..           ...        ...\n761   img_95.jpg  surprised\n762   img_96.jpg  surprised\n763   img_97.jpg      happy\n764   img_98.jpg      happy\n765   img_99.jpg      angry\n\n[766 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>surprised</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>disgust</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>surprised</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>surprised</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>angry</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def categorize(row):\n    if row['emotion'] == 'angry':\n        return 1\n    elif row['emotion'] == 'sad':\n        return 2\n    elif row['emotion'] == 'happy':\n        return 3\n    elif row['emotion'] == 'fear':\n        return 4\n    elif row['emotion'] == 'surprised':\n        return 5\n    elif row['emotion'] == 'disgust':\n        return 6\n    else:\n        return 7","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:00:57.311792Z","iopub.execute_input":"2023-01-26T12:00:57.312227Z","iopub.status.idle":"2023-01-26T12:00:57.325987Z","shell.execute_reply.started":"2023-01-26T12:00:57.312191Z","shell.execute_reply":"2023-01-26T12:00:57.324516Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_test['label'] = df_test.apply(lambda x: categorize(x), axis=1)\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:00:59.704043Z","iopub.execute_input":"2023-01-26T12:00:59.704400Z","iopub.status.idle":"2023-01-26T12:00:59.740247Z","shell.execute_reply.started":"2023-01-26T12:00:59.704370Z","shell.execute_reply":"2023-01-26T12:00:59.739401Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        filename    emotion  label\n0      img_1.jpg  surprised      5\n1     img_10.jpg    disgust      6\n2    img_100.jpg      angry      1\n3    img_101.jpg       fear      4\n4    img_102.jpg      angry      1\n..           ...        ...    ...\n761   img_95.jpg  surprised      5\n762   img_96.jpg  surprised      5\n763   img_97.jpg      happy      3\n764   img_98.jpg      happy      3\n765   img_99.jpg      angry      1\n\n[766 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>surprised</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>disgust</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>fear</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>surprised</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>surprised</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport csv\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:02.753080Z","iopub.execute_input":"2023-01-26T12:01:02.753462Z","iopub.status.idle":"2023-01-26T12:01:04.711863Z","shell.execute_reply.started":"2023-01-26T12:01:02.753421Z","shell.execute_reply":"2023-01-26T12:01:04.710866Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_data = []\n\nfor i in range(0, len(df)):\n    image, label = df.iloc[i]['filename'], df.iloc[i]['label']\n    path = '/kaggle/input/dsp-project/portrait_faces_preprocessed/portrait_faces_preprocessed/' + image\n    new_row = [path, int(label)]\n    training_data.append(new_row)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:08.256112Z","iopub.execute_input":"2023-01-26T12:01:08.256666Z","iopub.status.idle":"2023-01-26T12:01:10.038415Z","shell.execute_reply.started":"2023-01-26T12:01:08.256633Z","shell.execute_reply":"2023-01-26T12:01:10.037456Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(len(training_data))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:12.638822Z","iopub.execute_input":"2023-01-26T12:01:12.639191Z","iopub.status.idle":"2023-01-26T12:01:12.645157Z","shell.execute_reply.started":"2023-01-26T12:01:12.639160Z","shell.execute_reply":"2023-01-26T12:01:12.643833Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"5836\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set = training_data[0:int(len(training_data) * 0.8)]\nvalidation_set = training_data[int(len(training_data) * 0.8):]\nprint(len(train_set) + len(validation_set))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:15.336659Z","iopub.execute_input":"2023-01-26T12:01:15.337027Z","iopub.status.idle":"2023-01-26T12:01:15.343142Z","shell.execute_reply.started":"2023-01-26T12:01:15.336998Z","shell.execute_reply":"2023-01-26T12:01:15.342210Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"5836\n","output_type":"stream"}]},{"cell_type":"code","source":"test_set_filename = []\ntest_set = []\n\nfor i in range(0, len(df_test)):\n    image, label = df_test.iloc[i]['filename'].rsplit('/', 1)[-1], df_test.iloc[i]['label']\n    path = '/kaggle/input/dsp-project/cropped_images_preprocessed/cropped_images_preprocessed/' + image\n    new_row = [path, int(label)]\n    test_set_filename.append(image)\n    test_set.append(new_row)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:17.743384Z","iopub.execute_input":"2023-01-26T12:01:17.743770Z","iopub.status.idle":"2023-01-26T12:01:17.908941Z","shell.execute_reply.started":"2023-01-26T12:01:17.743739Z","shell.execute_reply":"2023-01-26T12:01:17.907994Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(len(test_set))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:20.463834Z","iopub.execute_input":"2023-01-26T12:01:20.464194Z","iopub.status.idle":"2023-01-26T12:01:20.469813Z","shell.execute_reply.started":"2023-01-26T12:01:20.464163Z","shell.execute_reply":"2023-01-26T12:01:20.468793Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"766\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a map for the labels and their codes\nlabels = ['angry', 'sad', 'happy', 'fear', 'surprise', 'disgust', 'neutral']\nclass_map = {}\ni = 1\n    \nfor label in labels:\n    class_map[i] = label\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:22.833852Z","iopub.execute_input":"2023-01-26T12:01:22.834228Z","iopub.status.idle":"2023-01-26T12:01:22.840020Z","shell.execute_reply.started":"2023-01-26T12:01:22.834196Z","shell.execute_reply":"2023-01-26T12:01:22.838720Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(class_map)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:24.841391Z","iopub.execute_input":"2023-01-26T12:01:24.842079Z","iopub.status.idle":"2023-01-26T12:01:24.847431Z","shell.execute_reply.started":"2023-01-26T12:01:24.842042Z","shell.execute_reply":"2023-01-26T12:01:24.846128Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{1: 'angry', 2: 'sad', 3: 'happy', 4: 'fear', 5: 'surprise', 6: 'disgust', 7: 'neutral'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Class for loading of the data\nclass own_data(Dataset):\n    def __init__(self, train=0, transform=None):\n        if train == 0:\n            self.data = train_set\n        elif train == 1:\n            self.data = validation_set\n        else:\n            self.data = test_set\n            \n        self.transform = transform\n        self.to_pil = ToPILImage()\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, class_id = self.data[idx]\n        image = read_image(img_path)\n        \n        if self.transform:\n            image = self.transform(self.to_pil(image))\n        \n        return image, class_id","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:27.855275Z","iopub.execute_input":"2023-01-26T12:01:27.855947Z","iopub.status.idle":"2023-01-26T12:01:27.863125Z","shell.execute_reply.started":"2023-01-26T12:01:27.855907Z","shell.execute_reply":"2023-01-26T12:01:27.861927Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet50\n\nmodel = resnet50(pretrained=True)\nmodel.load_state_dict(torch.load('/kaggle/input/model-resnet50/resnet50_base'))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:30.759058Z","iopub.execute_input":"2023-01-26T12:01:30.759524Z","iopub.status.idle":"2023-01-26T12:01:38.954211Z","shell.execute_reply.started":"2023-01-26T12:01:30.759484Z","shell.execute_reply":"2023-01-26T12:01:38.953280Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98ddae8230cd46e88d25ff070fd11b36"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Freeze model parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\nfor param in model.layer4.parameters():\n    param.requires_grad = True\n    \n# Change the final layer of ResNet50 Model for Transfer Learning\nfc_inputs = model.fc.in_features\nmodel.fc = nn.Sequential(\n    nn.Linear(fc_inputs, 256),\n    nn.Dropout(0.2, inplace=False),\n    nn.BatchNorm1d(num_features=256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n    nn.Linear(256, 7),\n    nn.LogSoftmax(dim=1) # For using NLLLoss()/kldiv\n)\n\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:01:59.175233Z","iopub.execute_input":"2023-01-26T12:01:59.175603Z","iopub.status.idle":"2023-01-26T12:01:59.199122Z","shell.execute_reply.started":"2023-01-26T12:01:59.175572Z","shell.execute_reply":"2023-01-26T12:01:59.198088Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=2048, out_features=256, bias=True)\n    (1): Dropout(p=0.2, inplace=False)\n    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Linear(in_features=256, out_features=7, bias=True)\n    (4): LogSoftmax(dim=1)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocess = transforms.Compose([\n    transforms.Resize(256), \n    transforms.CenterCrop(size=224), \n    transforms.ToTensor(), \n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:10.572918Z","iopub.execute_input":"2023-01-26T12:02:10.573273Z","iopub.status.idle":"2023-01-26T12:02:10.578506Z","shell.execute_reply.started":"2023-01-26T12:02:10.573241Z","shell.execute_reply":"2023-01-26T12:02:10.577449Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Initialize the batch size\nbatch_size = 64\n\n# Load the train and test data\ntrain_data = own_data(0, preprocess)\nvalidation_data = own_data(1, preprocess)\ntest_data = own_data(2, preprocess)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:13.694501Z","iopub.execute_input":"2023-01-26T12:02:13.694869Z","iopub.status.idle":"2023-01-26T12:02:13.701700Z","shell.execute_reply.started":"2023-01-26T12:02:13.694839Z","shell.execute_reply":"2023-01-26T12:02:13.700601Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:17.746958Z","iopub.execute_input":"2023-01-26T12:02:17.747315Z","iopub.status.idle":"2023-01-26T12:02:17.756339Z","shell.execute_reply.started":"2023-01-26T12:02:17.747283Z","shell.execute_reply":"2023-01-26T12:02:17.755392Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=2048, out_features=256, bias=True)\n    (1): Dropout(p=0.2, inplace=False)\n    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Linear(in_features=256, out_features=7, bias=True)\n    (4): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"nll = nn.NLLLoss()\nadam = optim.Adam(model.parameters(), lr=3e-4)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:25.555889Z","iopub.execute_input":"2023-01-26T12:02:25.556239Z","iopub.status.idle":"2023-01-26T12:02:25.569143Z","shell.execute_reply.started":"2023-01-26T12:02:25.556208Z","shell.execute_reply":"2023-01-26T12:02:25.567389Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Define the train model function\ndef train_model(train_loader, model, loss_function, optimizer, batch_size, device=None):\n    for batch, (image, label) in enumerate(train_loader):\n        # Move labels and images to GPU\n        image = image.cuda()\n        label = label.cuda()\n\n        optimizer.zero_grad()\n        output = model(image)\n        label = label - 1\n        loss_func = loss_function(output, label)\n        loss_func.backward()\n        optimizer.step()\n        \n        if batch % 64 == 0:\n            print('[%5d] loss: %.3f' % (batch + 1, loss_func.item()))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:31.106548Z","iopub.execute_input":"2023-01-26T12:02:31.106919Z","iopub.status.idle":"2023-01-26T12:02:31.114530Z","shell.execute_reply.started":"2023-01-26T12:02:31.106888Z","shell.execute_reply":"2023-01-26T12:02:31.113465Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Test function\ndef validate_model(validation_loader, model, loss_function, batch_size, device=None):\n    size = len(validation_loader.dataset)\n    validation_loss, correct = 0, 0\n    \n    with torch.no_grad():\n        for image, label in validation_loader:\n            # Move labels and images to GPU\n            image = image.cuda()\n            label = label.cuda()\n            \n            output = model(image)\n            label = label - 1\n            validation_loss += loss_function(output, label).item()\n            correct += (output.argmax(1) == label).type(torch.float).sum().item()\n    \n    validation_loss /= batch_size\n    correct /= size\n    print(f\"Test error: \\n Accuracy: {(100 * correct):>0.01f}%, Avg loss: {validation_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:33.911249Z","iopub.execute_input":"2023-01-26T12:02:33.911940Z","iopub.status.idle":"2023-01-26T12:02:33.919423Z","shell.execute_reply.started":"2023-01-26T12:02:33.911905Z","shell.execute_reply":"2023-01-26T12:02:33.918283Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"device = None\n\nif device == None:\n    if torch.cuda.is_available():\n        print(\"CUDA used\")\n        device = torch.device('cuda')\n        model.cuda()\n\n        # Should be > 0\n        print(torch.cuda.device_count())\n\n        # Index of device used (can be 0)\n        print(torch.cuda.current_device())\n\n        # GPU location\n        print(torch.cuda.device(0))\n\n        # Name of GPU\n        print(torch.cuda.get_device_name(0))\n\n    else:\n        print(\"CPU used\")\n        device = torch.device('cpu')\n\n# Force CPU use\n# device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:38.769868Z","iopub.execute_input":"2023-01-26T12:02:38.770221Z","iopub.status.idle":"2023-01-26T12:02:41.748106Z","shell.execute_reply.started":"2023-01-26T12:02:38.770190Z","shell.execute_reply":"2023-01-26T12:02:41.747084Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"CUDA used\n1\n0\n<torch.cuda.device object at 0x7fd09332ae90>\nTesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 15\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    model.train()\n    train_model(train_loader, model, nll, adam, batch_size, device=device)\n    model.eval()\n    validate_model(validation_loader, model, nll, batch_size, device=device)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:02:44.539741Z","iopub.execute_input":"2023-01-26T12:02:44.540095Z","iopub.status.idle":"2023-01-26T12:08:49.933680Z","shell.execute_reply.started":"2023-01-26T12:02:44.540066Z","shell.execute_reply":"2023-01-26T12:08:49.932634Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\n[    1] loss: 2.089\n[   65] loss: 1.063\nTest error: \n Accuracy: 63.0%, Avg loss: 0.282806 \n\nEpoch 2\n-------------------------------\n[    1] loss: 0.697\n[   65] loss: 0.546\nTest error: \n Accuracy: 65.1%, Avg loss: 0.291637 \n\nEpoch 3\n-------------------------------\n[    1] loss: 0.163\n[   65] loss: 0.079\nTest error: \n Accuracy: 65.7%, Avg loss: 0.295397 \n\nEpoch 4\n-------------------------------\n[    1] loss: 0.036\n[   65] loss: 0.019\nTest error: \n Accuracy: 68.5%, Avg loss: 0.284302 \n\nEpoch 5\n-------------------------------\n[    1] loss: 0.029\n[   65] loss: 0.014\nTest error: \n Accuracy: 70.5%, Avg loss: 0.288862 \n\nEpoch 6\n-------------------------------\n[    1] loss: 0.006\n[   65] loss: 0.006\nTest error: \n Accuracy: 69.8%, Avg loss: 0.292546 \n\nEpoch 7\n-------------------------------\n[    1] loss: 0.009\n[   65] loss: 0.006\nTest error: \n Accuracy: 69.3%, Avg loss: 0.300371 \n\nEpoch 8\n-------------------------------\n[    1] loss: 0.005\n[   65] loss: 0.002\nTest error: \n Accuracy: 69.9%, Avg loss: 0.297528 \n\nEpoch 9\n-------------------------------\n[    1] loss: 0.003\n[   65] loss: 0.008\nTest error: \n Accuracy: 69.6%, Avg loss: 0.310096 \n\nEpoch 10\n-------------------------------\n[    1] loss: 0.003\n[   65] loss: 0.002\nTest error: \n Accuracy: 70.2%, Avg loss: 0.317545 \n\nEpoch 11\n-------------------------------\n[    1] loss: 0.001\n[   65] loss: 0.002\nTest error: \n Accuracy: 68.7%, Avg loss: 0.326690 \n\nEpoch 12\n-------------------------------\n[    1] loss: 0.003\n[   65] loss: 0.046\nTest error: \n Accuracy: 65.6%, Avg loss: 0.347644 \n\nEpoch 13\n-------------------------------\n[    1] loss: 0.019\n[   65] loss: 0.022\nTest error: \n Accuracy: 64.8%, Avg loss: 0.384601 \n\nEpoch 14\n-------------------------------\n[    1] loss: 0.045\n[   65] loss: 0.088\nTest error: \n Accuracy: 65.2%, Avg loss: 0.434309 \n\nEpoch 15\n-------------------------------\n[    1] loss: 0.068\n[   65] loss: 0.222\nTest error: \n Accuracy: 69.6%, Avg loss: 0.346257 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model_resnet50')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:11:04.168502Z","iopub.execute_input":"2023-01-26T12:11:04.168881Z","iopub.status.idle":"2023-01-26T12:11:04.345380Z","shell.execute_reply.started":"2023-01-26T12:11:04.168847Z","shell.execute_reply":"2023-01-26T12:11:04.344379Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\ndef test_model(test_loader, model, device=None):\n    predictions = []\n    \n    with torch.no_grad():\n        for image, label in test_loader:\n            # Move to GPU\n            image = image.cuda()\n            label = label.cuda()\n            \n            output = model(image)\n            prediction = (output.argmax(1)).cpu().detach().numpy()\n            predictions.extend(prediction)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:11:07.373018Z","iopub.execute_input":"2023-01-26T12:11:07.373379Z","iopub.status.idle":"2023-01-26T12:11:07.380390Z","shell.execute_reply.started":"2023-01-26T12:11:07.373347Z","shell.execute_reply":"2023-01-26T12:11:07.379444Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"predictions = test_model(test_loader, model, device)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:11:20.164689Z","iopub.execute_input":"2023-01-26T12:11:20.165123Z","iopub.status.idle":"2023-01-26T12:11:26.751711Z","shell.execute_reply.started":"2023-01-26T12:11:20.165077Z","shell.execute_reply":"2023-01-26T12:11:26.750753Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"predictions = [x + 1 for x in predictions]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:11:31.973217Z","iopub.execute_input":"2023-01-26T12:11:31.973586Z","iopub.status.idle":"2023-01-26T12:11:31.978872Z","shell.execute_reply.started":"2023-01-26T12:11:31.973554Z","shell.execute_reply":"2023-01-26T12:11:31.977670Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"rijks_prediction = pd.DataFrame(\n    {'filename': test_set_filename,\n     'label': predictions\n    }\n)\n\nrijks_prediction","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:11:34.769848Z","iopub.execute_input":"2023-01-26T12:11:34.770192Z","iopub.status.idle":"2023-01-26T12:11:34.784581Z","shell.execute_reply.started":"2023-01-26T12:11:34.770161Z","shell.execute_reply":"2023-01-26T12:11:34.783460Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"        filename  label\n0      img_1.jpg      4\n1     img_10.jpg      4\n2    img_100.jpg      6\n3    img_101.jpg      4\n4    img_102.jpg      6\n..           ...    ...\n761   img_95.jpg      4\n762   img_96.jpg      7\n763   img_97.jpg      3\n764   img_98.jpg      6\n765   img_99.jpg      6\n\n[766 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rijks_prediction.rename(columns = {'label': 'predicted_label'}, inplace=True)\nrijks_prediction['actual_label'] = df_test['label']\nrijks_prediction","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:11:56.518237Z","iopub.execute_input":"2023-01-26T12:11:56.518614Z","iopub.status.idle":"2023-01-26T12:11:56.534675Z","shell.execute_reply.started":"2023-01-26T12:11:56.518580Z","shell.execute_reply":"2023-01-26T12:11:56.533651Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"        filename  predicted_label  actual_label\n0      img_1.jpg                4             5\n1     img_10.jpg                4             6\n2    img_100.jpg                6             1\n3    img_101.jpg                4             4\n4    img_102.jpg                6             1\n..           ...              ...           ...\n761   img_95.jpg                4             5\n762   img_96.jpg                7             5\n763   img_97.jpg                3             3\n764   img_98.jpg                6             3\n765   img_99.jpg                6             1\n\n[766 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>predicted_label</th>\n      <th>actual_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"correct = (rijks_prediction['predicted_label'] == rijks_prediction['actual_label'])\naccuracy = (correct.sum() / correct.size) * 100\naccuracy","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:12:00.227788Z","iopub.execute_input":"2023-01-26T12:12:00.228148Z","iopub.status.idle":"2023-01-26T12:12:00.236734Z","shell.execute_reply.started":"2023-01-26T12:12:00.228117Z","shell.execute_reply":"2023-01-26T12:12:00.235816Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"22.845953002610965"},"metadata":{}}]},{"cell_type":"code","source":"rijks_prediction.to_csv('/kaggle/working/resnet50_predictions_15epochs', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T12:12:13.159197Z","iopub.execute_input":"2023-01-26T12:12:13.159569Z","iopub.status.idle":"2023-01-26T12:12:13.169086Z","shell.execute_reply.started":"2023-01-26T12:12:13.159537Z","shell.execute_reply":"2023-01-26T12:12:13.167991Z"},"trusted":true},"execution_count":32,"outputs":[]}]}