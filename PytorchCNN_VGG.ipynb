{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-26T11:40:12.854844Z","iopub.execute_input":"2023-01-26T11:40:12.855214Z","iopub.status.idle":"2023-01-26T11:40:12.877757Z","shell.execute_reply.started":"2023-01-26T11:40:12.855131Z","shell.execute_reply":"2023-01-26T11:40:12.876861Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dsp-project/portrait_emotions_labels.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:31.039615Z","iopub.execute_input":"2023-01-26T11:40:31.040537Z","iopub.status.idle":"2023-01-26T11:40:31.083878Z","shell.execute_reply.started":"2023-01-26T11:40:31.040502Z","shell.execute_reply":"2023-01-26T11:40:31.082722Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"             filename  emotion  label\n0     image_06637.jpg    angry      1\n1     image_06638.jpg    angry      1\n2     image_06639.jpg  disgust      6\n3     image_06641.jpg  neutral      7\n4     image_06642.jpg      sad      2\n...               ...      ...    ...\n5831  image_08036.jpg    angry      1\n5832  image_08035.jpg  neutral      7\n5833  image_08038.jpg      sad      2\n5834  image_08028.jpg     fear      4\n5835  image_08026.jpg    angry      1\n\n[5836 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_06637.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_06638.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_06639.jpg</td>\n      <td>disgust</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_06641.jpg</td>\n      <td>neutral</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_06642.jpg</td>\n      <td>sad</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5831</th>\n      <td>image_08036.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5832</th>\n      <td>image_08035.jpg</td>\n      <td>neutral</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5833</th>\n      <td>image_08038.jpg</td>\n      <td>sad</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5834</th>\n      <td>image_08028.jpg</td>\n      <td>fear</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5835</th>\n      <td>image_08026.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5836 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/dsp-project/rijks_emotion_cluster1.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:33.510138Z","iopub.execute_input":"2023-01-26T11:40:33.510498Z","iopub.status.idle":"2023-01-26T11:40:33.530596Z","shell.execute_reply.started":"2023-01-26T11:40:33.510470Z","shell.execute_reply":"2023-01-26T11:40:33.529654Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        filename    emotion\n0      img_1.jpg  surprised\n1     img_10.jpg    disgust\n2    img_100.jpg      angry\n3    img_101.jpg       fear\n4    img_102.jpg      angry\n..           ...        ...\n761   img_95.jpg  surprised\n762   img_96.jpg  surprised\n763   img_97.jpg      happy\n764   img_98.jpg      happy\n765   img_99.jpg      angry\n\n[766 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>surprised</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>disgust</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>surprised</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>surprised</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>angry</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def categorize(row):\n    if row['emotion'] == 'angry':\n        return 1\n    elif row['emotion'] == 'sad':\n        return 2\n    elif row['emotion'] == 'happy':\n        return 3\n    elif row['emotion'] == 'fear':\n        return 4\n    elif row['emotion'] == 'surprised':\n        return 5\n    elif row['emotion'] == 'disgust':\n        return 6\n    else:\n        return 7","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:37.278109Z","iopub.execute_input":"2023-01-26T11:40:37.278469Z","iopub.status.idle":"2023-01-26T11:40:37.284724Z","shell.execute_reply.started":"2023-01-26T11:40:37.278438Z","shell.execute_reply":"2023-01-26T11:40:37.283554Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_test['label'] = df_test.apply(lambda x: categorize(x), axis=1)\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:40.692596Z","iopub.execute_input":"2023-01-26T11:40:40.693206Z","iopub.status.idle":"2023-01-26T11:40:40.729505Z","shell.execute_reply.started":"2023-01-26T11:40:40.693170Z","shell.execute_reply":"2023-01-26T11:40:40.728594Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        filename    emotion  label\n0      img_1.jpg  surprised      5\n1     img_10.jpg    disgust      6\n2    img_100.jpg      angry      1\n3    img_101.jpg       fear      4\n4    img_102.jpg      angry      1\n..           ...        ...    ...\n761   img_95.jpg  surprised      5\n762   img_96.jpg  surprised      5\n763   img_97.jpg      happy      3\n764   img_98.jpg      happy      3\n765   img_99.jpg      angry      1\n\n[766 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>emotion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>surprised</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>disgust</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>fear</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>surprised</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>surprised</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>angry</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport csv\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:44.367222Z","iopub.execute_input":"2023-01-26T11:40:44.367692Z","iopub.status.idle":"2023-01-26T11:40:46.463954Z","shell.execute_reply.started":"2023-01-26T11:40:44.367633Z","shell.execute_reply":"2023-01-26T11:40:46.463009Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_data = []\n\nfor i in range(0, len(df)):\n    image, label = df.iloc[i]['filename'], df.iloc[i]['label']\n    path = '/kaggle/input/dsp-project/portrait_faces_preprocessed/portrait_faces_preprocessed/' + image\n    new_row = [path, int(label)]\n    training_data.append(new_row)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:50.306405Z","iopub.execute_input":"2023-01-26T11:40:50.306939Z","iopub.status.idle":"2023-01-26T11:40:52.048250Z","shell.execute_reply.started":"2023-01-26T11:40:50.306898Z","shell.execute_reply":"2023-01-26T11:40:52.047272Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(len(training_data))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:53.608397Z","iopub.execute_input":"2023-01-26T11:40:53.608775Z","iopub.status.idle":"2023-01-26T11:40:53.614848Z","shell.execute_reply.started":"2023-01-26T11:40:53.608743Z","shell.execute_reply":"2023-01-26T11:40:53.613754Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"5836\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set = training_data[0:int(len(training_data) * 0.8)]\nvalidation_set = training_data[int(len(training_data) * 0.8):]\nprint(len(train_set) + len(validation_set))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:56.365873Z","iopub.execute_input":"2023-01-26T11:40:56.366314Z","iopub.status.idle":"2023-01-26T11:40:56.375738Z","shell.execute_reply.started":"2023-01-26T11:40:56.366278Z","shell.execute_reply":"2023-01-26T11:40:56.373150Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"5836\n","output_type":"stream"}]},{"cell_type":"code","source":"test_set_filename = []\ntest_set = []\n\nfor i in range(0, len(df_test)):\n    image, label = df_test.iloc[i]['filename'].rsplit('/', 1)[-1], df_test.iloc[i]['label']\n    path = '/kaggle/input/dsp-project/cropped_images_preprocessed/cropped_images_preprocessed/' + image\n    new_row = [path, int(label)]\n    test_set_filename.append(image)\n    test_set.append(new_row)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:40:59.496504Z","iopub.execute_input":"2023-01-26T11:40:59.496881Z","iopub.status.idle":"2023-01-26T11:40:59.667341Z","shell.execute_reply.started":"2023-01-26T11:40:59.496848Z","shell.execute_reply":"2023-01-26T11:40:59.666333Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(len(test_set))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:41:01.905379Z","iopub.execute_input":"2023-01-26T11:41:01.905753Z","iopub.status.idle":"2023-01-26T11:41:01.911255Z","shell.execute_reply.started":"2023-01-26T11:41:01.905721Z","shell.execute_reply":"2023-01-26T11:41:01.910282Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"766\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a map for the labels and their codes\nlabels = ['angry', 'sad', 'happy', 'fear', 'surprise', 'disgust', 'neutral']\nclass_map = {}\ni = 1\n    \nfor label in labels:\n    class_map[i] = label\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:41:04.223048Z","iopub.execute_input":"2023-01-26T11:41:04.223462Z","iopub.status.idle":"2023-01-26T11:41:04.230396Z","shell.execute_reply.started":"2023-01-26T11:41:04.223426Z","shell.execute_reply":"2023-01-26T11:41:04.229037Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(class_map)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:41:07.538483Z","iopub.execute_input":"2023-01-26T11:41:07.538871Z","iopub.status.idle":"2023-01-26T11:41:07.544544Z","shell.execute_reply.started":"2023-01-26T11:41:07.538833Z","shell.execute_reply":"2023-01-26T11:41:07.543398Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{1: 'angry', 2: 'sad', 3: 'happy', 4: 'fear', 5: 'surprise', 6: 'disgust', 7: 'neutral'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Class for loading of the data\nclass own_data(Dataset):\n    def __init__(self, train=0, transform=None):\n        if train == 0:\n            self.data = train_set\n        elif train == 1:\n            self.data = validation_set\n        else:\n            self.data = test_set\n            \n        self.transform = transform\n        self.to_pil = ToPILImage()\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, class_id = self.data[idx]\n        image = read_image(img_path)\n        \n        if self.transform:\n            image = self.transform(self.to_pil(image))\n        \n        return image, class_id","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:41:14.581177Z","iopub.execute_input":"2023-01-26T11:41:14.581545Z","iopub.status.idle":"2023-01-26T11:41:14.591826Z","shell.execute_reply.started":"2023-01-26T11:41:14.581514Z","shell.execute_reply":"2023-01-26T11:41:14.590726Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import vgg19\n\nmodel = vgg19(pretrained=True)\nmodel.load_state_dict(torch.load('/kaggle/input/model-vgg19/vgg19_base'))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:41:17.778965Z","iopub.execute_input":"2023-01-26T11:41:17.779393Z","iopub.status.idle":"2023-01-26T11:44:03.670651Z","shell.execute_reply.started":"2023-01-26T11:41:17.779347Z","shell.execute_reply":"2023-01-26T11:44:03.669606Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f58dd3285514cd8bf415cf31e1304d3"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Freeze model parameters\nfor param in model.parameters():\n    param.requires_grad = False\n    \n# Change the final layer of VGG-19 Model for Transfer Learning\nmodel.classifier = nn.Sequential(\n    nn.Linear(in_features=25088, out_features=4096), \n    nn.ReLU(inplace=True), \n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=4096, out_features=4096, bias=True), \n    nn.ReLU(inplace=True), \n    nn.Dropout(p=0.5, inplace=False), \n    nn.Linear(in_features=4096, out_features=7, bias=True)\n)\n\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:44:24.619551Z","iopub.execute_input":"2023-01-26T11:44:24.620632Z","iopub.status.idle":"2023-01-26T11:44:25.798592Z","shell.execute_reply.started":"2023-01-26T11:44:24.620576Z","shell.execute_reply":"2023-01-26T11:44:25.797453Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): ReLU(inplace=True)\n    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): ReLU(inplace=True)\n    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (33): ReLU(inplace=True)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): ReLU(inplace=True)\n    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=7, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocess = transforms.Compose([\n    transforms.Resize(256), \n    transforms.CenterCrop(size=224), \n    transforms.ToTensor(), \n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:45:28.496538Z","iopub.execute_input":"2023-01-26T11:45:28.496916Z","iopub.status.idle":"2023-01-26T11:45:28.502599Z","shell.execute_reply.started":"2023-01-26T11:45:28.496873Z","shell.execute_reply":"2023-01-26T11:45:28.501527Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Initialize the batch size\nbatch_size = 64\n\n# Load the train and test data\ntrain_data = own_data(0, preprocess)\nvalidation_data = own_data(1, preprocess)\ntest_data = own_data(2, preprocess)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:46:58.118614Z","iopub.execute_input":"2023-01-26T11:46:58.119327Z","iopub.status.idle":"2023-01-26T11:46:58.125049Z","shell.execute_reply.started":"2023-01-26T11:46:58.119289Z","shell.execute_reply":"2023-01-26T11:46:58.124080Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:47:01.304764Z","iopub.execute_input":"2023-01-26T11:47:01.305127Z","iopub.status.idle":"2023-01-26T11:47:01.312488Z","shell.execute_reply.started":"2023-01-26T11:47:01.305099Z","shell.execute_reply":"2023-01-26T11:47:01.311046Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): ReLU(inplace=True)\n    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): ReLU(inplace=True)\n    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (33): ReLU(inplace=True)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): ReLU(inplace=True)\n    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=7, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"cross = nn.CrossEntropyLoss()\nsgd = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:47:06.215729Z","iopub.execute_input":"2023-01-26T11:47:06.216729Z","iopub.status.idle":"2023-01-26T11:47:06.223659Z","shell.execute_reply.started":"2023-01-26T11:47:06.216652Z","shell.execute_reply":"2023-01-26T11:47:06.222618Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Define the train model function\ndef train_model(train_loader, model, loss_function, optimizer, batch_size, device=None):\n    for batch, (image, label) in enumerate(train_loader):\n        # Move labels and images to GPU\n        image = image.cuda()\n        label = label.cuda()\n\n        optimizer.zero_grad()\n        output = model(image)\n        label = label - 1\n        loss_func = loss_function(output, label)\n        loss_func.backward()\n        optimizer.step()\n        \n        if batch % 64 == 0:\n            print('[%5d] loss: %.3f' % (batch + 1, loss_func.item()))","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:47:10.149181Z","iopub.execute_input":"2023-01-26T11:47:10.149543Z","iopub.status.idle":"2023-01-26T11:47:10.157103Z","shell.execute_reply.started":"2023-01-26T11:47:10.149511Z","shell.execute_reply":"2023-01-26T11:47:10.155801Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Test function\ndef validate_model(validation_loader, model, loss_function, batch_size, device=None):\n    size = len(validation_loader.dataset)\n    validation_loss, correct = 0, 0\n    \n    with torch.no_grad():\n        for image, label in validation_loader:\n            # Move labels and images to GPU\n            image = image.cuda()\n            label = label.cuda()\n            \n            output = model(image)\n            label = label - 1\n            validation_loss += loss_function(output, label).item()\n            correct += (output.argmax(1) == label).type(torch.float).sum().item()\n    \n    validation_loss /= batch_size\n    correct /= size\n    print(f\"Test error: \\n Accuracy: {(100 * correct):>0.01f}%, Avg loss: {validation_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:47:14.828383Z","iopub.execute_input":"2023-01-26T11:47:14.828786Z","iopub.status.idle":"2023-01-26T11:47:14.836346Z","shell.execute_reply.started":"2023-01-26T11:47:14.828753Z","shell.execute_reply":"2023-01-26T11:47:14.835210Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"device = None\n\nif device == None:\n    if torch.cuda.is_available():\n        print(\"CUDA used\")\n        device = torch.device('cuda')\n        model.cuda()\n\n        # Should be > 0\n        print(torch.cuda.device_count())\n\n        # Index of device used (can be 0)\n        print(torch.cuda.current_device())\n\n        # GPU location\n        print(torch.cuda.device(0))\n\n        # Name of GPU\n        print(torch.cuda.get_device_name(0))\n\n    else:\n        print(\"CPU used\")\n        device = torch.device('cpu')\n\n# Force CPU use\n# device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:47:19.959598Z","iopub.execute_input":"2023-01-26T11:47:19.959975Z","iopub.status.idle":"2023-01-26T11:47:22.922055Z","shell.execute_reply.started":"2023-01-26T11:47:19.959945Z","shell.execute_reply":"2023-01-26T11:47:22.920902Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"CUDA used\n1\n0\n<torch.cuda.device object at 0x7f46a6706f10>\nTesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 15\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    model.train()\n    train_model(train_loader, model, cross, sgd, batch_size, device=device)\n    model.eval()\n    validate_model(validation_loader, model, cross, batch_size, device=device)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:47:26.256447Z","iopub.execute_input":"2023-01-26T11:47:26.256831Z","iopub.status.idle":"2023-01-26T11:54:04.453967Z","shell.execute_reply.started":"2023-01-26T11:47:26.256798Z","shell.execute_reply":"2023-01-26T11:54:04.452944Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\n[    1] loss: 1.976\n[   65] loss: 1.330\nTest error: \n Accuracy: 59.5%, Avg loss: 0.351246 \n\nEpoch 2\n-------------------------------\n[    1] loss: 1.109\n[   65] loss: 0.966\nTest error: \n Accuracy: 66.7%, Avg loss: 0.266271 \n\nEpoch 3\n-------------------------------\n[    1] loss: 1.103\n[   65] loss: 0.825\nTest error: \n Accuracy: 68.6%, Avg loss: 0.240385 \n\nEpoch 4\n-------------------------------\n[    1] loss: 0.772\n[   65] loss: 0.597\nTest error: \n Accuracy: 70.4%, Avg loss: 0.227558 \n\nEpoch 5\n-------------------------------\n[    1] loss: 0.656\n[   65] loss: 0.704\nTest error: \n Accuracy: 70.9%, Avg loss: 0.220732 \n\nEpoch 6\n-------------------------------\n[    1] loss: 0.746\n[   65] loss: 0.545\nTest error: \n Accuracy: 71.2%, Avg loss: 0.213660 \n\nEpoch 7\n-------------------------------\n[    1] loss: 0.424\n[   65] loss: 0.512\nTest error: \n Accuracy: 72.3%, Avg loss: 0.214789 \n\nEpoch 8\n-------------------------------\n[    1] loss: 0.579\n[   65] loss: 0.510\nTest error: \n Accuracy: 72.2%, Avg loss: 0.219633 \n\nEpoch 9\n-------------------------------\n[    1] loss: 0.669\n[   65] loss: 0.489\nTest error: \n Accuracy: 72.2%, Avg loss: 0.219034 \n\nEpoch 10\n-------------------------------\n[    1] loss: 0.349\n[   65] loss: 0.254\nTest error: \n Accuracy: 71.8%, Avg loss: 0.223217 \n\nEpoch 11\n-------------------------------\n[    1] loss: 0.330\n[   65] loss: 0.300\nTest error: \n Accuracy: 71.9%, Avg loss: 0.224409 \n\nEpoch 12\n-------------------------------\n[    1] loss: 0.242\n[   65] loss: 0.200\nTest error: \n Accuracy: 71.9%, Avg loss: 0.224743 \n\nEpoch 13\n-------------------------------\n[    1] loss: 0.206\n[   65] loss: 0.217\nTest error: \n Accuracy: 72.3%, Avg loss: 0.235585 \n\nEpoch 14\n-------------------------------\n[    1] loss: 0.125\n[   65] loss: 0.192\nTest error: \n Accuracy: 71.7%, Avg loss: 0.242330 \n\nEpoch 15\n-------------------------------\n[    1] loss: 0.098\n[   65] loss: 0.215\nTest error: \n Accuracy: 70.3%, Avg loss: 0.247732 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model_vgg19')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:54:17.435954Z","iopub.execute_input":"2023-01-26T11:54:17.436315Z","iopub.status.idle":"2023-01-26T11:54:18.914797Z","shell.execute_reply.started":"2023-01-26T11:54:17.436283Z","shell.execute_reply":"2023-01-26T11:54:18.913817Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\ndef test_model(test_loader, model, device=None):\n    predictions = []\n    \n    with torch.no_grad():\n        for image, label in test_loader:\n            # Move to GPU\n            image = image.to(device)\n            label = label.to(device)\n            \n            output = model(image)\n            prediction = (output.argmax(1)).cpu().detach().numpy()\n            predictions.extend(prediction)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:55:17.623067Z","iopub.execute_input":"2023-01-26T11:55:17.623471Z","iopub.status.idle":"2023-01-26T11:55:17.630462Z","shell.execute_reply.started":"2023-01-26T11:55:17.623437Z","shell.execute_reply":"2023-01-26T11:55:17.629375Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"predictions = test_model(test_loader, model, device)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:55:21.098413Z","iopub.execute_input":"2023-01-26T11:55:21.098956Z","iopub.status.idle":"2023-01-26T11:55:30.664076Z","shell.execute_reply.started":"2023-01-26T11:55:21.098916Z","shell.execute_reply":"2023-01-26T11:55:30.663049Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"predictions = [x + 1 for x in predictions]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:56:10.241926Z","iopub.execute_input":"2023-01-26T11:56:10.242284Z","iopub.status.idle":"2023-01-26T11:56:10.247671Z","shell.execute_reply.started":"2023-01-26T11:56:10.242253Z","shell.execute_reply":"2023-01-26T11:56:10.246176Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"rijks_prediction = pd.DataFrame(\n    {'filename': test_set_filename,\n     'label': predictions\n    }\n)\n\nrijks_prediction","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:56:14.453114Z","iopub.execute_input":"2023-01-26T11:56:14.453477Z","iopub.status.idle":"2023-01-26T11:56:14.466648Z","shell.execute_reply.started":"2023-01-26T11:56:14.453447Z","shell.execute_reply":"2023-01-26T11:56:14.465736Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"        filename  label\n0      img_1.jpg      3\n1     img_10.jpg      4\n2    img_100.jpg      2\n3    img_101.jpg      3\n4    img_102.jpg      6\n..           ...    ...\n761   img_95.jpg      4\n762   img_96.jpg      3\n763   img_97.jpg      3\n764   img_98.jpg      3\n765   img_99.jpg      6\n\n[766 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rijks_prediction.rename(columns = {'label': 'predicted_label'}, inplace=True)\nrijks_prediction['actual_label'] = df_test['label']\nrijks_prediction","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:56:22.948155Z","iopub.execute_input":"2023-01-26T11:56:22.948531Z","iopub.status.idle":"2023-01-26T11:56:22.964860Z","shell.execute_reply.started":"2023-01-26T11:56:22.948500Z","shell.execute_reply":"2023-01-26T11:56:22.963735Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"        filename  predicted_label  actual_label\n0      img_1.jpg                3             5\n1     img_10.jpg                4             6\n2    img_100.jpg                2             1\n3    img_101.jpg                3             4\n4    img_102.jpg                6             1\n..           ...              ...           ...\n761   img_95.jpg                4             5\n762   img_96.jpg                3             5\n763   img_97.jpg                3             3\n764   img_98.jpg                3             3\n765   img_99.jpg                6             1\n\n[766 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>predicted_label</th>\n      <th>actual_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_101.jpg</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_102.jpg</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>img_95.jpg</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>img_96.jpg</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>img_97.jpg</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>img_98.jpg</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>img_99.jpg</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>766 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"correct = (rijks_prediction['predicted_label'] == rijks_prediction['actual_label'])\naccuracy = (correct.sum() / correct.size) * 100\naccuracy","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:56:26.185290Z","iopub.execute_input":"2023-01-26T11:56:26.185650Z","iopub.status.idle":"2023-01-26T11:56:26.194615Z","shell.execute_reply.started":"2023-01-26T11:56:26.185618Z","shell.execute_reply":"2023-01-26T11:56:26.193580Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"27.415143603133156"},"metadata":{}}]},{"cell_type":"code","source":"rijks_prediction.to_csv('/kaggle/working/vgg19_predictions_15epochs', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T11:57:03.123405Z","iopub.execute_input":"2023-01-26T11:57:03.123796Z","iopub.status.idle":"2023-01-26T11:57:03.133378Z","shell.execute_reply.started":"2023-01-26T11:57:03.123764Z","shell.execute_reply":"2023-01-26T11:57:03.132276Z"},"trusted":true},"execution_count":32,"outputs":[]}]}